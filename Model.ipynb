{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install PyTorch and Other Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image enhance technique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Image Enhancement Function\n",
    "def enhance_image(image):\n",
    "    # Convert to OpenCV format\n",
    "    image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Apply histogram equalization\n",
    "    equalized = cv2.equalizeHist(image)\n",
    "    \n",
    "    # Convert to PyTorch tensor and apply preprocessing\n",
    "    equalized = preprocess(equalized)\n",
    "    \n",
    "    return equalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNetModel, self).__init__()\n",
    "        # Define U-Net architecture\n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through U-Net\n",
    "        ...\n",
    "        return segmentation_mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNetModel, self).__init__()\n",
    "        # Load pre-trained ResNet\n",
    "        self.resnet = torchvision.models.resnet50(pretrained=True)\n",
    "        # Modify the last layer for binary classification\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through ResNet\n",
    "        output = self.resnet(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Model\n",
    "def predict(tile_image):\n",
    "    # Load models\n",
    "    unet_model = UNetModel()\n",
    "    resnet_model = ResNetModel()\n",
    "\n",
    "    # Enhance and resize the input tile image\n",
    "    enhanced_image = enhance_image(tile_image)\n",
    "\n",
    "    # Perform semantic segmentation using U-Net\n",
    "    segmentation_mask = unet_model(enhanced_image)\n",
    "    road_pixels, building_pixels = count_pixels(segmentation_mask)\n",
    "\n",
    "    # Perform image-level classification using ResNet\n",
    "    resnet_output = resnet_model(enhanced_image)\n",
    "    resnet_output = torch.softmax(resnet_output, dim=1)\n",
    "    _, pred_class = torch.max(resnet_output, 1)\n",
    "\n",
    "    # Combine outputs from U-Net and ResNet\n",
    "    if road_pixels > building_pixels and pred_class == 0:  # 0 for \"road-dominant\"\n",
    "        return \"Roads are more prominent\"\n",
    "    elif building_pixels > road_pixels and pred_class == 1:  # 1 for \"building-dominant\"\n",
    "        return \"Buildings are more prominent\"\n",
    "    else:\n",
    "        return \"Inconclusive\"\n",
    "\n",
    "# Helper function to count pixels in the segmentation mask\n",
    "def count_pixels(mask):\n",
    "    road_pixels = torch.sum(mask == 0)  # Assuming 0 is the road class\n",
    "    building_pixels = torch.sum(mask == 1)  # Assuming 1 is the building class\n",
    "    return road_pixels, building_pixels\n",
    "\n",
    "# Example usage\n",
    "tile_image = # Load an OpenStreetMap tile image\n",
    "result = predict(tile_image)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
